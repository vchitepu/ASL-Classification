{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A and F Classifier: The Brogrammers\n",
    "Vinay Chitepu<br>\n",
    "Delaney Gomen<br>\n",
    "Alexandra Isaly\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**NOTE:** Make sure to unzip the files in the directory before running.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATADIR = 'Training_Data'\n",
    "SCORE_DATADIR = 'TestingData'\n",
    "\n",
    "CATEGORIES = ['A', 'F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    #Gaussian blur\n",
    "    blur = cv2.GaussianBlur(img, (11,11), cv2.BORDER_DEFAULT)\n",
    "    \n",
    "    #Threshhold + Dilate + Erode\n",
    "    ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "    \n",
    "    #Apply background to make background white\n",
    "    imgRGB= cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    mask = sure_bg\n",
    "    imgCopy = img.copy()\n",
    "    imgCopy[mask==0] = 255\n",
    "    \n",
    "    return imgCopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data = 'Training', img_size = 100, preprocess = False):\n",
    "    \n",
    "    if data.upper() == 'TRAINING': d = os.path.join(os.getcwd(), TRAIN_DATADIR)\n",
    "    elif data.upper() == 'TESTING': d = os.path.join(os.getcwd(), SCORE_DATADIR)\n",
    "    else: print(\"Incorrect paramter\")\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    for cat in CATEGORIES:\n",
    "        path = os.path.join(d, cat)\n",
    "        label = CATEGORIES.index(cat)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array = cv2.resize(img_array, (img_size,img_size))\n",
    "                if preprocess:\n",
    "                    img_array = process_image(img_array)\n",
    "                data.append(img_array)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    data = np.array(data)\n",
    "    data = data.reshape(data.shape[0], img_size, img_size, 1)\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(data='Training', img_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100x100 image but has like\n",
    "X[45].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\19548\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\19548\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Initializing model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = X.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Layer 4\n",
    "model.add(Flatten())  # Converts 2-D to 1-D\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling Model\n",
    "model.compile(loss = 'binary_crossentropy',   # There are only 2 classes\n",
    "             optimizer = 'adam',              # Optimization Function\n",
    "             metrics = ['accuracy'])          # Using accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 61 samples\n",
      "WARNING:tensorflow:From C:\\Users\\19548\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "140/140 [==============================] - 2s 13ms/sample - loss: 0.7153 - acc: 0.5071 - val_loss: 0.7036 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.3890 - acc: 0.8786 - val_loss: 1.7940 - val_acc: 0.1475\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.1720 - acc: 0.9643 - val_loss: 1.6548 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0471 - acc: 0.9857 - val_loss: 1.3676 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0437 - acc: 0.9857 - val_loss: 2.0769 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0751 - acc: 0.9571 - val_loss: 0.9617 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 2.6400 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 2.9328 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0377 - acc: 0.9929 - val_loss: 2.0007 - val_acc: 0.0492\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0490 - acc: 0.9786 - val_loss: 3.1642 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0091 - acc: 0.992 - 1s 7ms/sample - loss: 0.0090 - acc: 0.9929 - val_loss: 0.3544 - val_acc: 0.9180\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.5672 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 1.5779 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0127 - acc: 0.9929 - val_loss: 1.1037 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 0.0520 - acc: 0.9786 - val_loss: 1.2974 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 1s 8ms/sample - loss: 0.0497 - acc: 0.9857 - val_loss: 2.3182 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 1s 8ms/sample - loss: 6.1763e-04 - acc: 1.0000 - val_loss: 2.6158 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 5.4614e-04 - acc: 1.0000 - val_loss: 2.5712 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 2.6126e-05 - acc: 1.0000 - val_loss: 2.5454 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 1s 7ms/sample - loss: 4.1820e-04 - acc: 1.0000 - val_loss: 2.4876 - val_acc: 0.7049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19d0ca7d128>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=3, epochs=20, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('easy_model.h5')\n",
    "# model.save('easy_model_backup.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('easy_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/sample - loss: 1.0960e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.096046740182525e-07, 1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = load_data(data='Testing', img_size=64, preprocess=True)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []; b = []; yell = [];\n",
    "for i in range(len(y_test)):\n",
    "    a.append(y_test[i])\n",
    "    b.append(preds[i])\n",
    "    if y_test[i] == preds[i]:\n",
    "        yell.append(True)\n",
    "    else:\n",
    "        yell.append(False)\n",
    "\n",
    "predictions = pd.DataFrame(data={'Actual': a, 'Prediction': b, 'Correct': yell })\n",
    "\n",
    "def conv_to_letters(ent):\n",
    "    i = ent\n",
    "    if i == 0:\n",
    "        i = 'a'\n",
    "    else:\n",
    "        i = 'f'\n",
    "    return i\n",
    "        \n",
    "predictions.Actual = predictions.Actual.apply(conv_to_letters)\n",
    "predictions.Prediction = predictions.Prediction.apply(conv_to_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting out wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Actual, Prediction, Correct]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[predictions.Correct == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_labels = np.array(predictions.Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a',\n",
       "       'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a',\n",
       "       'a', 'a', 'a', 'a', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',\n",
       "       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f',\n",
       "       'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w') as file:\n",
    "    file.write(str(est_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
